#!/bin/bash

DOMAIN="$1"
TARGET_DATE="$2"

if [ -z "$DOMAIN" ] || [ -z "$TARGET_DATE" ]; then
    echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 DOMAIN TARGET_DATE"
    echo "–ü—Ä–∏–º–µ—Ä: $0 ba.org.ua 20191115"
    echo "TARGET_DATE –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYYMMDD"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
if ! [[ "$TARGET_DATE" =~ ^[0-9]{8}$ ]]; then
    echo "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ YYYYMMDD"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–∞—Å—Ç–µ—Ä-—Å–ø–∏—Å–∫–∞
MASTER_LIST="${DOMAIN}_master_list.json"
if [ ! -f "$MASTER_LIST" ]; then
    echo "‚ùå –ú–∞—Å—Ç–µ—Ä-—Å–ø–∏—Å–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: $MASTER_LIST"
    echo "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: ./create_master_list.sh $DOMAIN"
    exit 1
fi

echo "üïê –ü–æ–∏—Å–∫ —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –¥–ª—è $DOMAIN –Ω–∞ –¥–∞—Ç—É $TARGET_DATE"
echo "=============================================================="

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–∞—Ç—ã ¬± –¥–Ω–∏
calculate_date() {
    local base_date="$1"
    local days_offset="$2"

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º YYYYMMDD –≤ —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD –¥–ª—è date
    local formatted_date="${base_date:0:4}-${base_date:4:2}-${base_date:6:2}"

    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—É—é –¥–∞—Ç—É
    if command -v gdate >/dev/null 2>&1; then
        # macOS (GNU date via homebrew)
        gdate -d "$formatted_date $days_offset days" +%Y%m%d
    else
        # Linux
        date -d "$formatted_date $days_offset days" +%Y%m%d
    fi
}

# –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ ¬±90 –¥–Ω–µ–π
FROM_DATE=$(calculate_date "$TARGET_DATE" "-90")
TO_DATE=$(calculate_date "$TARGET_DATE" "90")

echo "üìÖ –í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ: $FROM_DATE - $TO_DATE"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–Ω–∞–ø—à–æ—Ç–∞
find_closest_snapshot() {
    local url="$1"
    local target_timestamp="$2"

    # –î–µ–ª–∞–µ–º CDX –∑–∞–ø—Ä–æ—Å –¥–ª—è URL –≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ
    local cdx_response
    cdx_response=$(curl -s "http://web.archive.org/cdx/search/cdx?url=$(printf '%s' "$url" | sed 's/ /%20/g')&from=$FROM_DATE&to=$TO_DATE&output=json&fl=timestamp,original,statuscode,mimetype,length&filter=statuscode:200&filter=mimetype:text/html" 2>/dev/null)

    if [ -z "$cdx_response" ] || [ "$cdx_response" = "[]" ]; then
        return 1
    fi

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –Ω–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π —Å–Ω–∞–ø—à–æ—Ç
    echo "$cdx_response" | jq -r --arg target "$target_timestamp" '
    if length > 1 then
      .[1:] | map({
        timestamp: .[0],
        original: .[1],
        statuscode: .[2],
        mimetype: .[3],
        size: (.[4] | tonumber? // 0),
        diff: (.[0] | tonumber) - ($target | tonumber) | if . < 0 then -. else . end
      }) | sort_by(.diff) | .[0] | {
        archive_url: ("https://web.archive.org/web/" + .timestamp + "/" + .original),
        timestamp: .timestamp,
        original_url: .original,
        statuscode: .statuscode,
        size: .size,
        days_diff: (.diff / 1000000 | floor)
      }
    else
      empty
    end'
}

# –ß–∏—Ç–∞–µ–º –º–∞—Å—Ç–µ—Ä-—Å–ø–∏—Å–æ–∫ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π URL
SNAPSHOT_FILE="${DOMAIN}_snapshots_${TARGET_DATE}.json"
TEMP_FILE="${SNAPSHOT_FILE}.tmp"

echo "üîç –ü–æ–∏—Å–∫ —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –¥–ª—è URL –∏–∑ –º–∞—Å—Ç–µ—Ä-—Å–ø–∏—Å–∫–∞..."

# –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
echo "[]" > "$TEMP_FILE"

total_urls=$(jq length "$MASTER_LIST")
current_url=0
found_snapshots=0

echo "üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é $total_urls URL..."

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π URL –∏–∑ –º–∞—Å—Ç–µ—Ä-—Å–ø–∏—Å–∫–∞
jq -r '.[].original' "$MASTER_LIST" | while read -r url; do
    current_url=$((current_url + 1))

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 URL
    if [ $((current_url % 50)) -eq 0 ] || [ "$current_url" -eq 1 ]; then
        echo "  üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: $current_url/$total_urls"
    fi

    # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π —Å–Ω–∞–ø—à–æ—Ç
    snapshot_info=$(find_closest_snapshot "$url" "${TARGET_DATE}000000")

    if [ -n "$snapshot_info" ] && [ "$snapshot_info" != "null" ]; then
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Å–Ω–∞–ø—à–æ—Ç –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
        jq --argjson new_snapshot "$snapshot_info" '. += [$new_snapshot]' "$TEMP_FILE" > "${TEMP_FILE}.new" && mv "${TEMP_FILE}.new" "$TEMP_FILE"
        found_snapshots=$((found_snapshots + 1))
    fi

    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è rate limit
    sleep 0.5
done

# –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π
mv "$TEMP_FILE" "$SNAPSHOT_FILE"

# –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
final_count=$(jq length "$SNAPSHOT_FILE" 2>/dev/null || echo "0")

echo ""
echo "‚úÖ –ü–û–ò–°–ö –°–ù–ê–ü–®–û–¢–û–í –ó–ê–í–ï–†–®–ï–ù!"
echo "=============================="
echo "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:"
echo "  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ URL: $total_urls"
echo "  –ù–∞–π–¥–µ–Ω–æ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: $final_count"
echo "  –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: $(( final_count * 100 / total_urls ))%"

if [ "$final_count" -gt 0 ]; then
    echo ""
    echo "üéØ –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤:"
    jq -r '.[:5] | .[] | "  \(.days_diff) –¥–Ω–µ–π: \(.original_url)"' "$SNAPSHOT_FILE"

    echo ""
    echo "üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—é –æ—Ç —Ü–µ–ª–µ–≤–æ–π –¥–∞—Ç—ã:"
    jq -r 'group_by(.days_diff) | map({days: .[0].days_diff, count: length}) | sort_by(.days) | .[] | "  \(.days) –¥–Ω–µ–π: \(.count) —Å–Ω–∞–ø—à–æ—Ç–æ–≤"' "$SNAPSHOT_FILE" | head -10
fi

echo ""
echo "üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: $SNAPSHOT_FILE"
echo ""
echo "üöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"
echo "poetry run wayback-analyzer download-snapshot $DOMAIN --date $TARGET_DATE"